{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc0957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matti/code/Apps/TextualMediaSearcher/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc13e69",
   "metadata": {},
   "source": [
    "## Embeddings models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf14e52",
   "metadata": {},
   "source": [
    "\n",
    "#### BERT (AutoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbc2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finnish language embedding model\n",
    "model_name = \"TurkuNLP/bert-base-finnish-cased-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def embed_sentences(sents: list[str] | str) -> np.ndarray:\n",
    "    if not isinstance(sents, list):\n",
    "        sents = [sents]\n",
    "    inputs = tokenizer(sents, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        return embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478430b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"Koirilla on pentuja.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1) # sentence embedding (shape: (batch, hidden_size))\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431cec80",
   "metadata": {},
   "source": [
    "#### Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e6ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "def embed_sentences(sents: list[str] | str) -> np.ndarray:\n",
    "    \"\"\"  \"\"\"\n",
    "    if not isinstance(sents, list):\n",
    "        sents = [sents]\n",
    "    return model.encode(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a715c6d",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d0821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example text\n",
    "text = \"\"\n",
    "with open('suomi_text.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line != \"\\n\":\n",
    "            text += line.replace(\"\\n\", \"\").strip() + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a25aa3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0/159\n",
      "  16/159\n",
      "  32/159\n",
      "  48/159\n",
      "  64/159\n",
      "  80/159\n",
      "  96/159\n",
      " 112/159\n",
      " 128/159\n",
      " 144/159\n"
     ]
    }
   ],
   "source": [
    "# get sentence embeddings\n",
    "sents = sent_tokenize(text)\n",
    "batch_size = 16\n",
    "\n",
    "embeddings_size = model.get_sentence_embedding_dimension()\n",
    "sent_embeddings = np.zeros((len(sents), embeddings_size), dtype=\"float32\")\n",
    "for i in range(0, len(sents), batch_size):\n",
    "    print(\" {:>3}/{}\".format(i, len(sents)))\n",
    "    batch = sents[i : i+batch_size]\n",
    "    batch_embeds = embed_sentences(batch)\n",
    "    sent_embeddings[i:i+batch_size, :] = batch_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f153eb8",
   "metadata": {},
   "source": [
    "#### Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1281da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "import pickle\n",
    "id2idx = {}\n",
    "data = {\n",
    "    \"embeddings\": sent_embeddings,\n",
    "    \"id2idx\": id2idx,\n",
    "}\n",
    "with open(\"sent_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9f76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "with open(\"sent_embeddings.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "sent_embeddings = data['embeddings']\n",
    "id2idx = data['id2idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aae9a0",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21e62fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6892  |  Suomen asema hyökkäyksessä oli pitkään epäselvä, mutta sille oli joka tapauksessa varattu siinä rooli.\n",
      "0.6491  |  Venäjän vallan aika oli Suomen kannalta yksi historian rauhallisimmista kausista (vain Oolannin sota kosketti Suomen aluetta), mutta jonkin verran suomalaisia vapaaehtoisjoukkoja tai upseereita taisteli Venäjän lipun alla Manner-Euroopassa ja Aasiassa.\n",
      "0.6450  |  Suomen asema välirauhan aikaan talvisodan jälkeen oli ollut hyvin tukala ja poliittinen liikkumavara oli niukka.\n",
      "0.6267  |  Nyt Suomi nähtiin tärkeänä osana hyökkäyksessä itään.\n",
      "0.6215  |  Alkuvaiheessa kuitenkin talonpoikainen nostoväki oli edelleen sotavoimien ydinjoukkona.\n"
     ]
    }
   ],
   "source": [
    "# SIMILARITY\n",
    "text = \"Suomi oli venäjän vallan alla\"\n",
    "query_emb = embed_sentences(text)\n",
    "sims = cosine_similarity(sent_embeddings, query_emb).squeeze()\n",
    "sorted_idx = np.flip( np.argsort(sims, axis=0) )[:100].squeeze()\n",
    "pairs = np.array((sorted_idx, sims[sorted_idx])).T\n",
    "for idx, sim in pairs[:5]:\n",
    "    sent = sents[int(idx)]\n",
    "    print(f\"{sim:.4f}  |  {sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd86f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextualMediaSearcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
